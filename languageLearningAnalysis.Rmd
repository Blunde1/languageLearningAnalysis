---
title: "Analyse av language-learning data"
output:
  html_document:
    code_folding: hide
abstract: "
  Dokumentet tar utgangspunkt i målingene fra language-learning prosjektet.
  Analysene er gjort under antagelse av at forsøkspersonene er samplet fra samme initiell fordeling.
  Denne antagelsen kan diskuteres. 
  Resultatet av målingene blir først presentert visuelt, for så å bli analysert med statistiske tester på marginalt nivå.
  Null-hypotesen, at forventningen er lik for LIN og Helsfyr for en gitt måling, blir ikke forkastet når hver dimensjonene <finn bedre ord> er testet hver for seg.
  Av de åtte målingene så er resultatene fra \\<insert-measurement-type\\> de resultatene som er nærmest å forkaste en individuell null-hypotese.
  Dette blir klart etter inspeksjon av differanser etter en standardisering av de ulike dimensjonene, see Figur \\<sett inn fig-number\\>.
  Merk likevel at strengere krav til signifikans må stilles når flere hypoteser blir testet samtidig, dette grunnet multippel-testing-problem \\<sett-inn-en-bra-referanse\\>.
  Denne standardiseringen viser at alle gjennomsnitt for progresjon i de ulike dimensjonene i Helsfyr er mindre enn korresponderende gjennomsnitt ved LIN.
  En statistisk test er utviklet for å teste en null-hypotese (at summen av standardiserte målinger er like) mot en alternativ (at de er ulike / Helsfyr < LIN).
  Denne testen forkaster/forkaster ikke null hypotesen på <konfidens>-nivå.
  Dette er et første resultat på at språklig progresjon er lik/ulik for de to ulike skolene.
  Følgelig motiverer det til økt interesse, spørsmålsstilling og forskning rundt status-quo i norsk språkundervisningen.
  "
---

### Målinger og data
I tabellen under er data fra Tabell 1 til Tabell 8 insatt.
Denne er utgangspunktet for analysene som vil bli gjort.
Merk at "Helsfyr" er forkortet til "HLF". Dette er en konvensjon for resten av dokumentet.

Dokumentet snakker om forventninger, som er matematisk definert for en tilfeldig variabel, $X$, ved $E[X]=\int xdP_X(x)$ der $E[X]$ og $P_X(x)$ er forventningen og den kumulative fordelingen til $X$.
For den ikke-matematiske, så kan man tenke på forventningen som det _underliggende og strukturelle_ til en gruppe observasjoner -- nemlig det som vil vere gjennomsnittet gitt at man har mange nok observasjoner.

En antagelse som er gjort for alle testene som nå blir gjort er at forsøkspersonene er samplet fra den samme fordelingen. Dette er en antagelse som diverre trolig ikke holder, og som er diskutert i seksjon \<insert-relevant-section-in-main-document\>.
Målingene viser differanser (see seksjon \<section\> for detaljer).
En naturlig antagelse for forventningen til en språklig kunnskapskurve, er at denne er strengt økene i konstant og uniform læring over tid.
Dette medfører at forventningen til en differanse i kunnskap (altså læring) av typen i tabellen under ikke skal vere negativ. Dette er heller ikke tilfelle.
En naturlig antagelse til for forventningen til en språklig læringskurve (differanse i kunnskap), er at differansen i læring er avtagende gitt høyere kunnskap. 
Dette er av praktisk betydning, fordi forsøkspersonene ved ved LIN var analfabeter, mens de ved Helsfyr i stor grad ikke var dette. 
Siden utgangspunktet ikke er likt, er det ikke gitt at det er en naturlig null hypotese å anta at forventningen i læring (bestemt av en måling i tabellen under) er lik for Helsfyr og LIN. 
En mer naturlig null-hypotese er at forsøkspersonene ved LIN har større forventet læring enn forsøkspersonene ved Helsfyr.
Begge disse hypotesene vil bli testet.

Et interessant spørsmål er hva det totale bildet av alle målingene sier.
Statistisk sett er dette et komplisert spørsmål, av den enkle grunn at _de ulike dimensjonene ikke kan antas å vere uavhengige_. 
I den siste seksjonen i dokumentet støtter vi oss på at gruppe-målingene er gjennomsnitt, og vil ha en fordeling som tenderer mot en normalfordeling.
Når målingene er standardiserte og i så måte har lik skala, kan vi stille spørsmål rundt summen av gjennomsnittene for LIN og HLF. 
Normalfordelingen sin kovariansmatrise hjelper oss å ta hensyn til avhengigheten mellom dimensjonene.

Mye statistisk teori baserer seg på at funksjoner tenderer mot (ofte kvadratiske) standard funksjonsuttrykk jo mer data vi har. 
For eksempel, så vil et gjennomsnitt vere eksakt normalfordelt (Gaussisk fordeling) når vi har uendelig mye data.
I language-learning prosjektet har vi 5 observasjoner fra HLF og 7 fra LIN.
Diverre er det slik at $5<7<\infty$.
Å benytte tendensen mot normalfordeling for fordelingen til gjennomsnitt blir likevel ofte sett på som grei når vi har mer enn 30 observasjoner. 
Dette har vi dessverre ikke for hver enkelt måling, men hvor mange _effektive observasjoner_ vi har for det det totale antall målinger er uklart. 
Men det vil ligge et sted mellom `12` (målingene er fullstendig avhengige) og `r 12*8` (målingene er uavhengige).
Dette vil vi estimere.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyr)
library(dplyr)
library(ggplot2)
library(lazyeval) # interp function
library(purrr)
library(kableExtra)
library(GGally)

cbp <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

```{r create-data}
llData <- data.frame(
  "School" = c(rep("LIN", 7), rep("HLF", 5)),
  "Table 1" = c(0.225, NA, 0.1, 0.375, 0.4, NA, 0.067,
                0.175, 0.435, 0.1, 0.067, 0.175),
  "Table 2" = c(2.2224, 4, 0.2847, 2.0412, 2.7784, 2.1429, 1.1763, 
                0.6131, 4.0275, 0.4979, 1.5455, 2.2944),
  "Table 3" = c(0.3093, 1.3091, 0.2917, 0.1513, 0.0848, 1.3636, -0.2113, 
                0.0086, 0.3527, -0.0459, -2.2622, 0.1770),
  "Table 4" = c(-0.1143, 0.6246, -0.2732, 0.2853, -0.2179, 0.7273, 0.1292,
                0.0933, 0.0573, 0.3067, 0.1345, 0.1364),
  "Table 5" = c(0.0, 0.9231, 0.0833, 0.1207, -0.0133, 1.0, 0.1865,
                0.2188, 0.0903, 0.3497, 0.1364, 0.0357),
  "Table 6" = c(-0.0101, 0.1111, -0.0088, 0.0722, 0.0293, 0.1333, -0.0339,
                0.0026, 0.0110, 0.0597, 0.0060, 0.0158),
  "Table 7" = c(-0.1367, 0.6, 0.0802, 0.2619, 0.1372, 0.75, 0.2619,
                0.2111, 0.0058, 0.4502, 0.0756, 0.1152),
  "Table 8" = c(-0.0909, 0.4545, 0.2323, 0.31, 0.147, 0.5833, 0.2148,
                0.2515, 0.1, 0.375, 0.0365, 0.1909)
)
names(llData) = c("school", "T1", "T2", "T3", "T4", "T5", "T6", "T7", "T8")
test_cols <- names(llData)[-1]
llData$Group <- llData$school
llData$Group[is.na(llData$T1)] <- "LIN-T1-Missing"
llData <- llData %>% 
  mutate(school=factor(school, levels=unique(school))) %>%
  mutate(Group = factor(Group, levels=unique(Group)))
```


```{r look-at-wide-data}
llData %>%
    kbl(caption = "Measurement-data for the students at LIN and HLF. See <insert-reference-here> for a detailed explanation of the measurement methodology.",
        title = "Measurement-data") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


### Marginale hypotesetester

```{r parallel-cooredinate-plot, fig.cap="Observasjoner av målinger i Tabell 1 til 8. Observasjonane er standardiserte for å oppnå en felles skala. Forsøkspersonene med manglende observasjon i Tabell 1 er gruppert i oransj.", warning=FALSE}
colNames <- colnames(llData[,2:9])
transformedData <- data.frame(sapply(2:9, function(j){
  x <- llData[,j]
  (x - mean(x,na.rm=T))/sd(x,na.rm=T)
}))
colnames(transformedData) <- colnames(llData[,2:9])
transformedData$Group <- llData$Group
transformedData$StudentNum <- 1:nrow(llData)
dataLong <- gather(transformedData, condition, measurement, T1:T8, factor_key=TRUE)
dataLong$conditionNumeric <- as.numeric(dataLong$condition)
dataLong %>%
  ggplot(aes(x=conditionNumeric,y=measurement,group=StudentNum)) +
  geom_point(aes(colour=Group)) + 
  geom_line(aes(colour=Group)) + 
  scale_x_continuous(breaks = 1:8, labels=colNames) + 
  ylab("Standardiserte målinger") + 
  xlab("Tabell") + 
  theme_bw() +
  scale_colour_manual(values=cbp) + 
  theme(legend.position = "top") + 
  ggtitle("Parallell-koordinat plot for målinger")
```

La at gruppe $A$ er HLF og gruppe $B$ er LIN.
La $\mu=E[X]$ vere forventningen til en variabel.
Den klassiske statistiske testen for å teste

- $H0: \mu_A = \mu_B$,

mot 

- $H1: \mu_A \neq \mu_B$,

er en t-test \<insert-reference\>.
Når vi har et ulikt antall observasjoner i hver gruppe, $n_A\neq n_B$, og i tillegg ikke vil gjøre antagelser om lik varians i gruppa $A$ og $B$, benytter man typen Welch's t-test.
Dette er tilfelle for våre data -- vi ønsker ikke å gjøre unødvendige antagelser om for eksempel lik varians.

En t-test har antagelser om normalitet, som ikke kan antas å holde når vi har lite data i hver gruppe.
Dette er tilfelle når vi har $n_A=5$ og $n_B=7$.
For å lette på antagelsene om normalitet tester vi i tillegg til klassisk Welch's t-test en parametrisk bootstrap Welch t-test \<insert-reference\>. 
Algoritme 1 illustrerer denne testen.

******
**Algoritme 1**:  Welch's t-test parametrisk bootstrap

******

**Input**

- Gruppe-observasjoner $\mathbf{x}=\{x_i\}_{i=1}^{n_A}$, $\mathbf{y}=\{y_i\}_{i=1}^{n_B}$.
- Antall bootstrap iterasjoner $B$.

**Do**

1. La $T$ vere test-statistic fra en Welch's t-test mellom $\mathbf{x}^{(b)}$ og $\mathbf{y}^{(b)}$.
2. La $\overline{x},~\overline{y}$ og $\overline{z}$ vere gjennomsnittet i $\mathbf{x}$, $\mathbf{y}$ respektivt, i tillegg til gjennomsnittet i den samlede gruppen av alle observasjoner i $\mathbf{x}$ og $\mathbf{y}$.
3.  Konstruer to grupper med observasjoner som tilfredstiller $H0$ eksakt:
    a) $\mathbf{x}^{(0)} = \{x_i^{(0)} = x_i - \overline{x} + \overline{z}\}$ for alle observasjoner i $\mathbf{x}$.
    a) $\mathbf{y}^{(0)} = \{y_i^{(0)} = x_i - \overline{y} + \overline{z}\}$ for alle observasjoner i $\mathbf{y}$.
4.  **for** $b=1:B$
    a) Konstruer $\mathbf{x}^{(b)}$ som en tilfeldig trukket mengde fra $\mathbf{x^{(0)}}$ med tilbakelegging.
    b) Konstruer $\mathbf{y}^{(b)}$ som en tilfeldig trukket mengde fra $\mathbf{y^{(0)}}$ med tilbakelegging.
    c) La $T^{(b)}$ vere test-statistic for en Welch's t-test mellom $\mathbf{x}^{(b)}$ og $\mathbf{y}^{(b)}$.

**Return**

- Returner bootstrap p-verdi $p_{\text{boot}}$: Proporsjonen av de $B$ tester med statistic større enn $T$:
    a. $p_{\text{boot}} = \frac{1}{B+1}\left[1 + \sum_{b=1}^B 1\left(\left|T^{(b)}\right|>\left|T\right|\right)   \right]$.

******

```{r boot-t-test}
boot.t.test <- function(x, y, B=100000, alpha=0.05){
  x <- x[is.finite(x)]
  y <- y[is.finite(y)]
  nx <- length(x)
  ny <- length(y)
  mx <- mean(x)
  my <- mean(y)
  mxy <- mean(c(x,y))
  tStatistic <- t.test(x,y)$statistic
  # Data satisfying H0
  xh0 <- x-mx+mxy
  yh0 <- y-my+mxy
  tStatisticBoot <- numeric(B)
  meanH0Boot <- numeric(B)
  for(b in 1:B){
    xb <- sample(xh0, nx, replace = TRUE)
    yb <- sample(yh0, ny, replace=TRUE)
    tStatisticBoot[b] <- t.test(xb, yb)$statistic
    meanH0Boot[b] <- mean(c(xb, yb))
  }
  pvalue <- (1 + sum(abs(tStatisticBoot)>abs(tStatistic))) / (B+1)
  CI <- quantile(meanH0Boot, c(alpha/2, 1-alpha/2))
  res <- list(
    pvalue = pvalue,
    CI = CI
  )
  return(res)
}
```

Ved å benytte Algoritme 1 kan vi i tillegg til p-verdi trekke ut $(1-\alpha)100$\% konfidensintervall der $\alpha$ er et satt signifikansnivå.
Tabell 2 og Figur 2 illustrerer applikasjon av Algoritme 1 på data i Tabell 1 med de to ulike skolene som gruppe.
Merk at testene er marginale, da de arbeider individuelt hver kolonne i Tabell 1.
Vi har derfor et typisk multippel-testing problem: Når 100 uavhengige tester blir utført på data som tilfredstiller H0 vil man forvente at $100\alpha$ tester vil vere signifikante på $(1-\alpha)100$ signifikansnivå.
Vi har 8 tester som ikke kan antas å vere uavhengige, og denne avhengigheten gjør det vanskelig å korrigere for multippel-testing.
Tabell 2 bør derfor leses som at *$H0$ blir ikkke forkastet i noe tilfelle individuelt*, og p-verdiene for dette må rapporteres med varsomhet.

```{r marginal-testing}
#llDataLong <- llData %>% 
#  gather(metric, measurement, `T1`:`T8`, factor_key=TRUE)

ind.lin <- llData$school == "LIN"
ind.hlf <- !ind.lin

res <- data.frame(matrix(NA,nrow=8, ncol=5))
colnames(res) <- c("table", "pvalue: t-test", "pvalue: bootstrapped t-test", "ci-lower", "ci-upper")
pvalueboot <- pvaluettest <- lower <- upper <- numeric(8)
for(j in 1:8){
  pvaluettest[j] <- t.test(llData[ind.lin, j+1], llData[ind.hlf, j+1])$p.value
  test <- boot.t.test(x=llData[ind.lin,j+1], y=llData[ind.hlf,j+1], B=1000)
  pvalueboot[j] <- test$pvalue
  lower[j] <- test$CI[1]
  upper[j] <- test$CI[2]
}
res$table <- colnames(llData[,2:9])
res$`pvalue: t-test` <- pvaluettest
res$`pvalue: bootstrapped t-test` <- pvalueboot
res$`ci-lower` <- lower
res$`ci-upper` <- upper

res %>%
  kbl(caption = "Tabell 2: p-verdier for marginale hypotesetester. Verdier fra Welch's t-test og parametrisk Bootstrappet test er begge rapport og samsvarer med hverandre. I tillegg er 95% Konfidensintervall (0.025 og 0.975 empiriske kvantiler) for forventningen til verdier i tabell 1 til 8 rapportert. De er generert fra bootstrapping under H0. Krav til signifikans er strengere når man ser på flere tester samtidig, som i essens vil føre til høyere p-verdier. Da ingen p-verdier er signifikante marginalt blir dette mindre viktig.") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```


```{r radial-plot, warning=FALSE}
df <- llData
test_cols <- names(df)[-c(1,10)]
# Standardize
df[,2:9] <- sapply(1:8, function(i) (df[,i+1] - mean(df[,i+1], na.rm=T))/sd(df[,i+1], na.rm=T))
# CI
ADJUST <- 5
mean_plus <- function(x, adjust=ADJUST)
{
  mean(x, na.rm=T) + adjust
}
ind.lin <- df$school == "LIN"
ind.hlf <- !ind.lin
df_poly <- data.frame(matrix(NA,nrow=8, ncol=3))
colnames(df_poly) <- c("metric", "lower", "upper")
pvalueboot <- pvaluettest <- lower <- upper <- numeric(8)
for(j in 1:8){
  pvaluettest[j] <- t.test(df[ind.lin, j+1], df[ind.hlf, j+1])$p.value
  test <- boot.t.test(x=df[ind.lin,j+1], y=df[ind.hlf,j+1], B=1000)
  pvalueboot[j] <- test$pvalue
  lower[j] <- test$CI[1]
  upper[j] <- test$CI[2]
}
df_poly$metric <- as.factor(colnames(df[,2:9]))
df_poly$`lower` <- lower + ADJUST
df_poly$`upper` <- upper + ADJUST
df_poly <- df_poly %>%
  gather(type_edge, measure_edge, lower:upper)
df_poly <- df_poly %>% tibble()
# Means
df_means <- df %>%
  group_by(school) %>%
  summarise_at(test_cols, mean_plus) %>%
  gather(measure, measurement, `T1`:`T8`, factor_key=TRUE)
# function requires 
rotate_data <- function(data, col, by_col) {
  lev <- levels(data[,by_col][[1]])
  num <- length(lev)
  dir <- rep(seq(((num - 1) * 360 / num), 0, length.out = num))
  data$dir_ <- map_dbl(1:nrow(data), function(x) {dir[match(data[x,by_col][[1]], lev)]})
  #col_num <- match("mpg", colnames(cars))
  #filter_criteria <- interp(~ which_column == col_num, which_column = as.name(col))
  expr <- lazyeval::interp(~x, x = as.name(col))
  data <- mutate_(data, .dots = setNames(list(expr), "plotX"))
  data <- mutate_(data, .dots = setNames(list(expr), "plotY"))
  data <- data %>%
    mutate(plotX = round(cos(dir_ * pi / 180) * plotX, 2),
           plotY = round(sin(dir_ * pi / 180) * plotY, 2))
  data
} 
# data points
confidence_band <- rotate_data(df_poly, "measure_edge", "metric")
confidence_band$id=1L
#confidence_band <- confidence_band[c(1:7,1,8:14,8),]
sjekk2 <- rotate_data(df_means[df_means$school=="LIN",], "measurement", "measure")
sjekk3 <- rotate_data(df_means[df_means$school=="HLF",], "measurement", "measure")
lim = max(df_poly$measure_edge*1.1)
line_length <- lim - 1
rl <- data_frame(dir = unique(sjekk2$dir_), l = rep(line_length, length(unique(sjekk2$dir_)))) %>% 
  mutate(plotX = cos(dir * pi / 180) * (l),
         plotY = sin(dir * pi / 180) * (l))
rl$xend <- 0
rl$yend <- 0
lb <- rl
lb$label <- levels(sjekk2$measure)
circleFun <- function(center=c(0,0), diameter=1, npoints=100, start=0, end=2, filled=TRUE){
  tt <- seq(start*pi, end*pi, length.out=npoints)
  df <- data.frame(
    x = center[1] + diameter / 2 * cos(tt),
    y = center[2] + diameter / 2 * sin(tt)
  )
  if(filled==TRUE) { #add a point at the center so the whole 'pie slice' is filled
    df <- rbind(df, center)
  }
  return(df)
}
circlegrid <- data_frame(dia = seq(lim / 4, 2 * lim, lim / 4))
circlegrid <- circlegrid %>% 
  mutate(data = map(dia, function(x) {
    df     <- circleFun(diameter = x, filled = FALSE)
    df$lev <- x
    df
  }))
plotcircles <- bind_rows(circlegrid$data)
plotcircles$lev <- as.factor(plotcircles$lev)
cl <- data_frame(x = as.numeric(levels(plotcircles$lev)), label = as.character(round(x - ADJUST,1)))
cl <- cl[cl$x <= lim,]
middle <- circleFun(diameter = 1, start=0, end=2, filled = FALSE)
# plot each layer with its own data and aesthetics
cbp <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
colsLegend <- c("Helsfyr"=cbp[2], "LIN"=cbp[3], "95%-confidence"="grey70")
fillLegend <- 
  p <- 
  ggplot() + 
  geom_segment(data = rl, aes(x = plotX, xend = xend, y = plotY, yend = yend), colour = cbp[1]) +
  geom_path   (data = plotcircles, aes(x = x, y = y, group = lev), colour = "grey50") + 
  geom_text   (data = cl, aes(x = -x, y = 1, label = label), colour = "grey40") +
  geom_polygon(data = middle, aes(x, y), fill = "grey50", colour = "black") + 
  geom_polygon(data = confidence_band, aes(y = plotY, x = plotX, group=id, subgroup=type_edge, fill="95%-confidence"), 
               size = 1, alpha = 0.6) +
  geom_path(data=sjekk2[c(1:nrow(sjekk2),1),], aes(y = plotY, x = plotX, colour = "LIN"), size = 1) +
  geom_point(data=sjekk2, aes(y = plotY, x = plotX), stat='identity', colour = cbp[3], size = 1) +
  geom_path(data=sjekk3[c(1:nrow(sjekk3),1),], aes(y = plotY, x = plotX, colour = "Helsfyr"), size = 1, linetype = "dashed") +
  geom_point(data=sjekk3, aes(y = plotY, x = plotX), stat='identity', colour = cbp[2], size = 1) +
  geom_text   (data = lb, aes(x = 1.2*plotX, y = 1.2*plotY, label = label), colour = "black") +
  ylim(-lim*1.2, lim*1.2) + xlim(-lim*1.2, lim*1.2) +
  scale_fill_manual(name=NULL, values=colsLegend) + 
  scale_color_manual(name="Gruppe", values=colsLegend) + 
  theme(
    axis.text  = element_blank(), 
    axis.title = element_blank(), 
    line       = element_blank(),
    rect       = element_blank()
  ) + 
  coord_equal() + 
  ggtitle("Radial-summary-plot for tabellar", 
          subtitle="Målingar i tabellar er standardiserte. Konfidensintervall funne ved bootstrapping under H0")
p
```


Figur 2 inviterer til dypere tankegang



\<insert $3\times 4$ figure with individual radial plots\>

\<insert table with marginal hypothesis testing, both two-sided and one-sided\>

\<insert figure with scaled t-test confidence bands + group-means in radial plot\>


### Hypotesetester for summen av målinger

Figur 2 viser at målingene for læring alltid er større for LIN enn de for HLF.
Spørsmålet vi her stiller er:

> Hvor ekstremt er det at alle målinger for LIN samtidig og i så stor grad er større enn de for HLF?

Dette spørsmålet er det svært vanskelig å svare på. 
Vi må først eksplisitt definere hva som er __ekstremt__, og hva en naturlig null-hypotese er. 



> Explain the naive independence assumption

> Explain not just HLF < LIN 0.5^8 (loose information about distance)

> Effective sample size!

> Do the math for the distribution of statistic under null-hypothesis (sum of averages are equal)

> Clearly define the assumptions and estimators etc.

\<insert table for hypothesis test for sum of measurements\>


### Conclusion

Write amazing conclusion
